{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "train = pd.read_json('../yummly/train.json')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing - Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine        0\n",
       "id             0\n",
       "ingredients    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine        object\n",
       "id              int64\n",
       "ingredients    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'romaine lettuce',\n",
       " u'black olives',\n",
       " u'grape tomatoes',\n",
       " u'garlic',\n",
       " u'pepper',\n",
       " u'purple onion',\n",
       " u'seasoning',\n",
       " u'garbanzo beans',\n",
       " u'feta cheese crumbles']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[0,'ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train.loc[0,'ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.cuisine.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "italian         7838\n",
       "mexican         6438\n",
       "southern_us     4320\n",
       "indian          3003\n",
       "chinese         2673\n",
       "french          2646\n",
       "cajun_creole    1546\n",
       "thai            1539\n",
       "japanese        1423\n",
       "greek           1175\n",
       "spanish          989\n",
       "korean           830\n",
       "vietnamese       825\n",
       "moroccan         821\n",
       "british          804\n",
       "filipino         755\n",
       "irish            667\n",
       "jamaican         526\n",
       "russian          489\n",
       "brazilian        467\n",
       "Name: cuisine, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('cuisine').count()\n",
    "train.cuisine.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Further Data Preprocessing - Cleaning/Exploration/Feature selection:*\n",
    "(Suggestions)\n",
    "\n",
    "* Convert all letters into lowercase\n",
    "* Strip unicode\n",
    "* Strip punctuation such as semicolons and commas\n",
    "* Strip parantheses and the strings they enclose\n",
    "* Do food descriptors add value to prediction or not\n",
    "* Do brand names of ingredients add value to prediction or not\n",
    "* Remove common ingredients such as salt\n",
    "* Remove 10 least frequently occuring ingredients in each cuisine\n",
    "* Tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['num_ingredients'] = train.ingredients.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  \n",
       "0                9  \n",
       "1               11  \n",
       "2               12  \n",
       "3                4  \n",
       "4               20  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>467</td>\n",
       "      <td>9.520343</td>\n",
       "      <td>5.555139</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>804</td>\n",
       "      <td>9.708955</td>\n",
       "      <td>4.165011</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>1546</td>\n",
       "      <td>12.617076</td>\n",
       "      <td>4.611601</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>2673</td>\n",
       "      <td>11.982791</td>\n",
       "      <td>4.042125</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>755</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.855135</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>2646</td>\n",
       "      <td>9.817838</td>\n",
       "      <td>4.144744</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>1175</td>\n",
       "      <td>10.182128</td>\n",
       "      <td>3.729461</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>3003</td>\n",
       "      <td>12.705961</td>\n",
       "      <td>5.016806</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>667</td>\n",
       "      <td>9.299850</td>\n",
       "      <td>3.700505</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>7838</td>\n",
       "      <td>9.909033</td>\n",
       "      <td>3.806708</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamaican</th>\n",
       "      <td>526</td>\n",
       "      <td>12.214829</td>\n",
       "      <td>4.763897</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>1423</td>\n",
       "      <td>9.735067</td>\n",
       "      <td>4.245882</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>830</td>\n",
       "      <td>11.284337</td>\n",
       "      <td>3.878880</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>6438</td>\n",
       "      <td>10.877446</td>\n",
       "      <td>4.660183</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moroccan</th>\n",
       "      <td>821</td>\n",
       "      <td>12.909866</td>\n",
       "      <td>4.799813</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>russian</th>\n",
       "      <td>489</td>\n",
       "      <td>10.224949</td>\n",
       "      <td>4.051223</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>4320</td>\n",
       "      <td>9.634954</td>\n",
       "      <td>3.869404</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>989</td>\n",
       "      <td>10.423660</td>\n",
       "      <td>4.160919</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>1539</td>\n",
       "      <td>12.545809</td>\n",
       "      <td>4.411794</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vietnamese</th>\n",
       "      <td>825</td>\n",
       "      <td>12.675152</td>\n",
       "      <td>5.256173</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count       mean       std  min  25%  50%  75%  max\n",
       "cuisine                                                          \n",
       "brazilian       467   9.520343  5.555139    2    5    9   13   59\n",
       "british         804   9.708955  4.165011    2    7    9   12   30\n",
       "cajun_creole   1546  12.617076  4.611601    2    9   12   16   31\n",
       "chinese        2673  11.982791  4.042125    2    9   12   14   38\n",
       "filipino        755  10.000000  3.855135    2    7   10   12   38\n",
       "french         2646   9.817838  4.144744    1    7    9   12   31\n",
       "greek          1175  10.182128  3.729461    1    7   10   12   27\n",
       "indian         3003  12.705961  5.016806    1    9   12   16   49\n",
       "irish           667   9.299850  3.700505    2    7    9   12   27\n",
       "italian        7838   9.909033  3.806708    1    7   10   12   65\n",
       "jamaican        526  12.214829  4.763897    2    9   12   15   35\n",
       "japanese       1423   9.735067  4.245882    1    7    9   12   34\n",
       "korean          830  11.284337  3.878880    2    9   11   14   29\n",
       "mexican        6438  10.877446  4.660183    1    7   10   14   52\n",
       "moroccan        821  12.909866  4.799813    2    9   13   16   31\n",
       "russian         489  10.224949  4.051223    2    7   10   13   25\n",
       "southern_us    4320   9.634954  3.869404    1    7    9   12   40\n",
       "spanish         989  10.423660  4.160919    1    7   10   13   35\n",
       "thai           1539  12.545809  4.411794    1    9   12   15   40\n",
       "vietnamese      825  12.675152  5.256173    1    9   12   16   31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('cuisine').num_ingredients.describe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['ingredient_length'] = train.ingredients.apply(lambda x:np.mean([len(item) for item in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \n",
       "0                9          12.000000  \n",
       "1               11          10.090909  \n",
       "2               12          10.333333  \n",
       "3                4           6.750000  \n",
       "4               20          10.100000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train.groupby('cuisine').ingredient_length.describe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Further Feature Engineering:*\n",
    "(Suggestions)\n",
    "\n",
    "* Stemming\n",
    "* Lemmatization    \n",
    "* Bigrams\n",
    "* Build Similarity groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['ingredients_str'] = train.ingredients.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[0,'ingredients_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.ingredients_str\n",
    "y = train.cuisine\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 3028)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'a taste of thai rice noodles', u'abalone', u'abbamele', u'absinthe', u'abura age', u'acai juice', u'accent', u'accent seasoning', u'accompaniment', u'achiote', u'achiote paste', u'achiote powder', u'acini di pepe', u'ackee', u'acorn squash', u'active dry yeast', u'adobo', u'adobo all purpose seasoning', u'adobo sauce', u'adobo seasoning', u'adobo style seasoning', u'adzuki beans', u'agar', u'agar agar flakes', u'agave nectar', u'agave tequila', u'aged balsamic vinegar', u'aged cheddar cheese', u'aged gouda', u'aged manchego cheese', u'ahi', u'ahi tuna steaks', u'aioli', u'ajinomoto', u'ajwain', u'aka miso', u'alaskan king crab legs', u'alaskan king salmon', u'albacore', u'albacore tuna in water', u'alcohol', u'ale', u'aleppo', u'aleppo pepper', u'alexia waffle fries', u'alfalfa sprouts', u'alfredo sauce', u'alfredo sauce mix', u'all beef hot dogs', u'all potato purpos', u'all purpose seasoning', u'all purpose unbleached flour', u'allspice', u'allspice berries', u'almond butter', u'almond extract', u'almond filling', u'almond flour', u'almond liqueur', u'almond meal', u'almond milk', u'almond oil', u'almond paste', u'almond syrup', u'almonds', u'aloe juice', u'alphabet pasta', u'alum', u'amaranth', u'amarena cherries', u'amaretti', u'amaretti cookies', u'amaretto', u'amaretto liqueur', u'amba', u'amber', u'amber rum', u'amberjack fillet', u'amchur', u'america', u'american cheese', u'american cheese food', u'american cheese slices', u'ammonium bicarbonate', u'amontillado sherry', u'ampalaya', u'anaheim chile', u'anasazi beans', u'ancho', u'ancho chile pepper', u'ancho chili ground pepper', u'ancho powder', u'anchovies', u'anchovy filets', u'anchovy fillets', u'anchovy paste', u'and carrot green pea', u'and cook drain pasta ziti', u'and fat free half half', u'andouille chicken sausage']\n"
     ]
    }
   ],
   "source": [
    "print(vect.get_feature_names()[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(token_pattern=r\"'([a-z ]+)'\")\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'a taste of thai rice noodles', u'abalone', u'abbamele', u'absinthe', u'abura age', u'acai juice', u'accent', u'accent seasoning', u'accompaniment', u'achiote', u'achiote paste', u'achiote powder', u'acini di pepe', u'ackee', u'acorn squash', u'active dry yeast', u'adobo', u'adobo all purpose seasoning', u'adobo sauce', u'adobo seasoning', u'adobo style seasoning', u'adzuki beans', u'agar', u'agar agar flakes', u'agave nectar', u'agave tequila', u'aged balsamic vinegar', u'aged cheddar cheese', u'aged gouda', u'aged manchego cheese', u'ahi', u'ahi tuna steaks', u'aioli', u'ajinomoto', u'ajwain', u'aka miso', u'alaskan king crab legs', u'alaskan king salmon', u'albacore', u'albacore tuna in water', u'alcohol', u'ale', u'aleppo', u'aleppo pepper', u'alexia waffle fries', u'alfalfa sprouts', u'alfredo sauce', u'alfredo sauce mix', u'all beef hot dogs', u'all potato purpos', u'all purpose seasoning', u'all purpose unbleached flour', u'allspice', u'allspice berries', u'almond butter', u'almond extract', u'almond filling', u'almond flour', u'almond liqueur', u'almond meal', u'almond milk', u'almond oil', u'almond paste', u'almond syrup', u'almonds', u'aloe juice', u'alphabet pasta', u'alum', u'amaranth', u'amarena cherries', u'amaretti', u'amaretti cookies', u'amaretto', u'amaretto liqueur', u'amba', u'amber', u'amber rum', u'amberjack fillet', u'amchur', u'america', u'american cheese', u'american cheese food', u'american cheese slices', u'ammonium bicarbonate', u'amontillado sherry', u'ampalaya', u'anaheim chile', u'anasazi beans', u'ancho', u'ancho chile pepper', u'ancho chili ground pepper', u'ancho powder', u'anchovies', u'anchovy filets', u'anchovy fillets', u'anchovy paste', u'and carrot green pea', u'and cook drain pasta ziti', u'and fat free half half', u'andouille chicken sausage']\n"
     ]
    }
   ],
   "source": [
    "print(vect.get_feature_names()[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tokens = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_counts = np.sum(X_dtm.toarray(), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6250,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame({'token':X_train_tokens, 'count':X_train_counts}).sort('count', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greek\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indian_dtm = X_dtm[np.array(y == 'indian'), :]\n",
    "greek_dtm = X_dtm[np.array(y == 'greek'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indian_counts = np.sum(indian_dtm.toarray(),axis=0)\n",
    "greek_counts = np.sum(greek_dtm.toarray(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame({'token':X_train_tokens, 'count':indian_counts}).sort('count', ascending=False).head(20)\n",
    "#pd.DataFrame({'token':X_train_tokens, 'count':greek_counts}).sort('count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_counts = pd.DataFrame({'token':X_train_tokens, 'indian':indian_counts,'greek':greek_counts})\n",
    "#token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_counts['indian'] = token_counts.indian + 1\n",
    "token_counts['greek'] = token_counts.greek + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a vectorizer and calculates the AUC\n",
    "def tokenize_test(vect):\n",
    "    \n",
    "    # Create document-term matrices using the vectorizer\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "    # Print the number of features that were generated\n",
    "    print('Features:', X_train_dtm.shape[1])\n",
    "    \n",
    "    # Use Multinomial Naive Bayes to calculate predicted probabilities\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "    pred = nb.predict(X_test_dtm)\n",
    "    \n",
    "    # Print the AUC\n",
    "    #print('AUC:', metrics.roc_auc_score(y_test, y_pred_prob))\n",
    "    #print(classification_report(y_test, pred,target_names=news_test.target_names))\n",
    "    print(score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 2864\n"
     ]
    }
   ],
   "source": [
    "# confirm that the AUC is identical to task 5 when using the default parameters\n",
    "from sklearn import metrics\n",
    "vect = CountVectorizer()\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomail Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Algorithms to compare:*\n",
    "(suggestions)\n",
    "\n",
    "* Logistic Regression\n",
    "* Random forests\n",
    "* Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72326159492833919"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "cv = StratifiedKFold(y,n_folds = 6)\n",
    "#cross_val_score(pipe, X, y, cv, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Hyper Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['countvectorizer__min_df'] = [1, 2, 3, 4]\n",
    "param_grid['multinomialnb__alpha'] = sp.stats.uniform(scale=1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 2.5 s, total: 1min 39s\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=Non..., vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "          fit_params={}, iid=True, n_iter=18, n_jobs=1,\n",
       "          param_distributions={'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x10ff46510>, 'countvectorizer__min_df': [1, 2, 3, 4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = RandomizedSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_iter=18, random_state=1)\n",
    "%time rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.74986, std: 0.00494, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.417022004702574, 'countvectorizer__min_df': 2},\n",
       " mean: 0.72462, std: 0.00446, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.7203244934421581, 'countvectorizer__min_df': 1},\n",
       " mean: 0.72723, std: 0.00601, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.00011437481734488664, 'countvectorizer__min_df': 4},\n",
       " mean: 0.74933, std: 0.00356, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.30233257263183977, 'countvectorizer__min_df': 4},\n",
       " mean: 0.71941, std: 0.00456, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.14675589081711304, 'countvectorizer__min_df': 4},\n",
       " mean: 0.75190, std: 0.00436, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.0923385947687978, 'countvectorizer__min_df': 1},\n",
       " mean: 0.75290, std: 0.00418, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.1862602113776709, 'countvectorizer__min_df': 1},\n",
       " mean: 0.72155, std: 0.00442, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.34556072704304774, 'countvectorizer__min_df': 2},\n",
       " mean: 0.74989, std: 0.00418, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.39676747423066994, 'countvectorizer__min_df': 3},\n",
       " mean: 0.72122, std: 0.00452, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.538816734003357, 'countvectorizer__min_df': 3},\n",
       " mean: 0.74943, std: 0.00449, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.4191945144032948, 'countvectorizer__min_df': 3},\n",
       " mean: 0.72135, std: 0.00500, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.6852195003967595, 'countvectorizer__min_df': 3},\n",
       " mean: 0.72032, std: 0.00433, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.20445224973151743, 'countvectorizer__min_df': 4},\n",
       " mean: 0.72133, std: 0.00502, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.8781174363909454, 'countvectorizer__min_df': 3},\n",
       " mean: 0.72022, std: 0.00408, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.027387593197926163, 'countvectorizer__min_df': 2},\n",
       " mean: 0.72125, std: 0.00479, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.6704675101784022, 'countvectorizer__min_df': 3},\n",
       " mean: 0.74883, std: 0.00305, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.41730480236712697, 'countvectorizer__min_df': 4},\n",
       " mean: 0.74783, std: 0.00528, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5586898284457517, 'countvectorizer__min_df': 2}]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752903907075\n",
      "{'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.1862602113776709, 'countvectorizer__min_df': 1}\n"
     ]
    }
   ],
   "source": [
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "import scipy as sp\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['countvectorizer__min_df'] = [1, 2, 3]\n",
    "param_grid['multinomialnb__alpha'] = [0,0.5,1]\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 2.47 s, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=Non..., vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': [0, 0.5, 1], 'countvectorizer__min_df': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass the pipeline (instead of just the model) to GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "%time grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.68565, std: 0.00426, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0, 'countvectorizer__min_df': 1},\n",
       " mean: 0.72439, std: 0.00472, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.5, 'countvectorizer__min_df': 1},\n",
       " mean: 0.72326, std: 0.00484, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 1, 'countvectorizer__min_df': 1},\n",
       " mean: 0.66106, std: 0.00576, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0, 'countvectorizer__min_df': 1},\n",
       " mean: 0.74770, std: 0.00460, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5, 'countvectorizer__min_df': 1},\n",
       " mean: 0.73229, std: 0.00552, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 1, 'countvectorizer__min_df': 1},\n",
       " mean: 0.68758, std: 0.00429, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0, 'countvectorizer__min_df': 2},\n",
       " mean: 0.72263, std: 0.00494, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.5, 'countvectorizer__min_df': 2},\n",
       " mean: 0.72309, std: 0.00458, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 1, 'countvectorizer__min_df': 2},\n",
       " mean: 0.67079, std: 0.00650, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0, 'countvectorizer__min_df': 2},\n",
       " mean: 0.74871, std: 0.00534, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5, 'countvectorizer__min_df': 2},\n",
       " mean: 0.73815, std: 0.00527, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 1, 'countvectorizer__min_df': 2},\n",
       " mean: 0.68892, std: 0.00389, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0, 'countvectorizer__min_df': 3},\n",
       " mean: 0.72067, std: 0.00462, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.5, 'countvectorizer__min_df': 3},\n",
       " mean: 0.72226, std: 0.00468, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 1, 'countvectorizer__min_df': 3},\n",
       " mean: 0.67697, std: 0.00598, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0, 'countvectorizer__min_df': 3},\n",
       " mean: 0.74850, std: 0.00435, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5, 'countvectorizer__min_df': 3},\n",
       " mean: 0.74084, std: 0.00377, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 1, 'countvectorizer__min_df': 3}]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the scores for each combination of parameters\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748705184291\n",
      "{'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5, 'countvectorizer__min_df': 2}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_json('../yummly/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['ingredients_str'] = test.ingredients.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = test.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'british', u'southern_us', u'italian', ..., u'italian',\n",
       "       u'southern_us', u'mexican'], \n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class_rand = rand.predict(X_test)\n",
    "pred_class_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 20)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_rand = rand.predict_proba(X_test)\n",
    "pred_prob_rand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':test.id, 'cuisine':pred_class_rand}).set_index('id').to_csv('sub1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
